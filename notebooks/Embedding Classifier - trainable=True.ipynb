{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; np.random.seed(0);\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "sys.path.insert(0, \"../src\")\n",
    "sys.path.insert(0, \"../\")\n",
    "import shutil\n",
    "from d2v_recommender import *\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(135359, 1) 125474\n"
     ]
    }
   ],
   "source": [
    "recommender = D2V_Recommender()\n",
    "recommender.load_rater_vec(config.rater_embeddings_path)\n",
    "recommender.load_rated_vec(config.rated_embeddings_path)\n",
    "print(recommender.mean_embeddings.shape, len(recommender.wv.index2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           rater   rated    m\n",
       "6168461    81684  188927  0.0\n",
       "14727985   32084   57368  0.0\n",
       "4478599    24899  114815  0.0\n",
       "9644512   104628   97280  0.0\n",
       "7947499    61534   26742  0.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rater</th>\n      <th>rated</th>\n      <th>m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6168461</th>\n      <td>81684</td>\n      <td>188927</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>14727985</th>\n      <td>32084</td>\n      <td>57368</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4478599</th>\n      <td>24899</td>\n      <td>114815</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9644512</th>\n      <td>104628</td>\n      <td>97280</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7947499</th>\n      <td>61534</td>\n      <td>26742</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train = pd.read_csv(config.train_data_path).sample(frac=1)\n",
    "x_train = train.iloc[:,:2].values\n",
    "y_train = train.iloc[:,2].values\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 125474/125474 [00:01<00:00, 84110.69it/s]\n"
     ]
    }
   ],
   "source": [
    "max_rater_idx, max_rated_idx, _ = train.max()\n",
    "\n",
    "offset_vector = np.zeros((1, config.d2v_params[\"embedding_size\"]))\n",
    "rater_embedding_matrix = np.vstack([offset_vector, np.stack(recommender.mean_embeddings.values[:,0])])\n",
    "\n",
    "rated_id_to_emb_idx = {}\n",
    "rated_embedding_matrix = np.zeros((int(max_rated_idx) + 1, config.d2v_params[\"embedding_size\"]))\n",
    "# unknown rated will have embedding of zero\n",
    "for user_id_str in tqdm(recommender.wv.vocab.keys()):\n",
    "    embedding_vector = recommender.wv[user_id_str]\n",
    "    if embedding_vector is not None:\n",
    "        user_id_int = int(user_id_str)\n",
    "        rated_embedding_matrix[user_id_int] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    " recommender.wv[\"10\"] - rated_embedding_matrix[10], rater_embedding_matrix[10] - recommender.mean_embeddings.loc[\"10\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 1, 100)       13536000    input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 1, 100)       22097100    input_2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 1, 200)       0           embedding[0][0]                  \n                                                                 embedding_1[0][0]                \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 1, 50)        10050       concatenate[0][0]                \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1, 25)        1275        dense[0][0]                      \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1, 1)         26          dense_1[0][0]                    \n==================================================================================================\nTotal params: 35,644,451\nTrainable params: 35,644,451\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Keras model with two unmutable embedding layers\n",
    "# We create them so as not to change the input data.\n",
    "\n",
    "from keras.layers import Embedding, concatenate, Dense\n",
    "from keras import Model, Input\n",
    "from keras.metrics import AUC\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "input_1 = Input(shape=(1,))\n",
    "emb_1 = Embedding(\n",
    "    int(max_rater_idx) + 1,\n",
    "    config.d2v_params[\"embedding_size\"],\n",
    "    weights = [rater_embedding_matrix],\n",
    "    trainable = True,\n",
    "    input_length=1,\n",
    ")\n",
    "emb_1 = emb_1(input_1)\n",
    "\n",
    "input_2 = Input(shape=(1,))\n",
    "emb_2 = Embedding(\n",
    "    int(max_rated_idx) + 1,\n",
    "    config.d2v_params[\"embedding_size\"],\n",
    "    weights = [rated_embedding_matrix],\n",
    "    trainable = True,\n",
    "    input_length=1,\n",
    ")\n",
    "emb_2 = emb_2(input_2)\n",
    "\n",
    "merge = concatenate([emb_1, emb_2])\n",
    "dense1 = Dense(50, activation='relu')(merge)\n",
    "dense2 = Dense(25, activation='relu')(dense1)\n",
    "dense3 = Dense(1, activation=\"sigmoid\")(dense2)\n",
    "\n",
    "# dense = Dense\n",
    "\n",
    "\n",
    "model = Model(inputs=[input_1, input_2], outputs=dense3)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy',AUC()])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/500\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f0a473cb950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f0a473cb950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: smac attempted to use a functionality that requires module emcee, but it couldn't be loaded. Please install emcee and retry.\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "   480/109853 [..............................] - ETA: 18:15:58 - loss: 0.4224 - accuracy: 0.8166 - auc: 0.8057"
     ]
    }
   ],
   "source": [
    "subset = len(x_train)+1  # all data\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=1,\n",
    "    mode='auto', baseline=None, restore_best_weights=True\n",
    ")\n",
    "history = model.fit([x_train[:subset,0], x_train[:subset,1]], \n",
    "            y_train[:subset], \n",
    "            validation_split=0.1,\n",
    "            epochs=500, \n",
    "            batch_size=128,\n",
    "            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(config.keras_model_trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 7), history.history['val_auc'], \"g\", range(1, 7), history.history['auc'], \"r\")\n",
    "plt.legend([\"Val\",\"Train\"])\n",
    "plt.axvline(x=5)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"ROC AUC (val_set)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation on test set\n",
    "test = pd.read_csv(config.test_data_path).sample(frac=1)\n",
    "x_test = test.iloc[:,:2].values\n",
    "y_test = test.iloc[:,2].values\n",
    "results = model.evaluate([x_test[:,0], x_test[:,1]], y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([x_test[:,0], x_test[:,1]])\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "#  https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/#:~:text=with%20sample%20code).-,ROC%20Curves%20and%20AUC%20in%20Python,probabilities%20for%20the%201%20class.\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, np.random.random(y_test.shape))\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, predictions.reshape(-1,1))\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='Random Classifier')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# plt the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
